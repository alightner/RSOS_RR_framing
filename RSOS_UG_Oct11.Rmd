---
title: Radical framing effects in the ultimatum game (Experimental Results, Discussion,
  and Supplementary Materials)
author: "Aaron D. Lightner, Pat Barclay, Edward H. Hagen"
output:
  html_document: default
  word_document: default
bibliography: RSOS_pt2_refs.bib
csl: vancouver.csl
---

```{r, echo=F, warning=F, message=F}
source('results.R')
```


## Results

We aimed to collect 60 pairs of participants in each of 4 conditions for a total N = 480. Based on our experience with attrition in our pilot study, we therefore recruited about 70 pairs of participants per condition. Following our *a priori* criteria, and before analyzing the data, participants were excluded if they did not complete the survey, which was determined by a failure to correctly enter a unique validation code at the end of the survey. This was only attainable if a participant correctly answered two attention check questions during the task, prior to reaching the validation code. These three exclusionary criteria were set out to remove from analyses participants less likely to be attentive. We also initially planned to exclude participants who finished the study too quickly (suggesting low attention), as seen in several participants in the pilot study, but because we were able to shorten the final study, that criterion did not apply to any participant. In addition, many other participants left the study beforehand, e.g., while the game was loading or after viewing the consent form (see Figure 5). After exclusions, we had a final sample of N = `r nrow(UG.data)`. We did not make any decisions on sample size based on observing the data.

```{r,echo=FALSE, fig.width=7, fig.height=5, fig.show='hold',fig.align='center'}

plot_attrition

```

**Figure 5.** Number of participants during each study phase. Individuals who completed the survey and attention checks (N=`r nrow(UG.data)`) comprised our "included"" sample for analysis.

Participants in our final sample included `r signif(nUS, 2)`% from the U.S., `r signif(nIN, 2)`% from India, `r signif(nOther,3)`% from various other regions (e.g., Europe, South America, Africa, Australia, North America non-U.S., Asia non-India), and `r signif(nUnsp, 2)`% unspecified or ambiguous responses. Participant ages ranged from `r signif(min.age, 2)` to `r signif(max.age, 2)` (mean = `r signif(mean.age, 2)`, SD = `r signif(sd.age, 2)`), with `r signif(male, 2)`% male and `r signif(female, 2)`% female. Based on Likert score responses, participants commonly lacked extensive experience with currency exchange (scale of 1-5 with 1 = no experience and 5 = extensive experience: mean = `r signif(ce1, 2)`, SD = `r signif(ce2, 2)`) and international travel (mean = `r signif(ce3, 2)`, SD = `r signif(ce4, 2)`). See Figures S5 and S6.

We refer to the condition with proposers in the banker role as the “banker condition”, and the condition with proposers in the customer role as the “customer condition”. In the banker and customer conditions, there did not appear to be a marked difference in the distribution of offers between the excluded participants who played the UG (but did not complete the survey) and the analyzed participants who completed the entire study (Figure 6). 

```{r echo=FALSE, warning=FALSE, fig.align='center', fig.width=10}
grid.arrange(p1,p2)
```

**Figure 6.** Distribution of proposers' offers by condition. Top row: offers of excluded participants. Bottom row: offers of included participants.

There was a large difference in the distribution of offers from excluded vs. included participants  in the windfall condition, however, where almost all excluded participants offered 0% but almost all included participants offered 50%, and also in the control condition, where more excluded participants offered 0% than 50% but almost all included participants offered 50%. Other interesting differences included that in the banker condition, a greater fraction of offers from excluded participants were either 0% or 100% compared to offers from included participants, and that in the customer condition a greater fraction of offers from excluded participants were either 0% or 50% compared to included participants. Henceforth, unless explicitly noted, all analyses will be of data from included participants only.

In our experiment, the central tendency differences between treatment and control conditions were significant and conformed to our predictions, with offers in the banker condition (mean = `r signif(mean(df$offer[df$condition=='banker']),3)`, SD = `r signif(sd(df$offer[df$condition=='banker']),3)`) significantly higher than the control condition (mean = `r signif(mean(df$offer[df$condition=='control']),3)`, SD = `r signif(sd(df$offer[df$condition=='control']),3)`, t = `r signif(t1$statistic,3)`, `r p.function(t1$p.value)`, Cohen's d = `r signif(cohen.bank$estimate,3)`) and offers in the customer condition (mean = `r signif(mean(df$offer[df$condition=='customer']),3)`, SD = `r signif(sd(df$offer[df$condition=='customer']),3)`) significantly lower than the control condition (t = `r signif(t2$statistic,3)`, `r p.function(t2$p.value)`, Cohen's d = `r signif(cohen.cust$estimate,3)`). See Table 2 and Figure 7.

```{r echo=FALSE, warning=FALSE}
tmp <- tidy(m_offers)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table 2. Logistic regression model of mean offers by condition. Estimates are log odds. The base condition is the banker condition. See Figure 7 for an effects plot.')
```


```{r echo=FALSE, warning=FALSE}
plot(allEffects(m_offers), main='')
```

**Figure 7.** Effect plot of the mean offer (as a proportion of the maximum possible offer) by condition. Bars indicate +/- 2 SE. Model coefficients are in Table 2. See text for details.


The data in each condition were not normally distributed (Shipiro Wilk: banker W = `r signif(shap1$statistic, 3)`, `r p.function(shap1$p.value)`; customer W = `r signif(shap2$statistic, 3)`, `r p.function(shap2$p.value)`; windfall W = `r signif(shap3$statistic, 3)`, `r p.function(shap3$p.value)`; control W = `r signif(shap4$statistic, 3)`, `r p.function(shap4$p.value)`). As stipulated in our *a priori* statistical analyses section we therefore also tested for differences in offers using a non-parametric Kruskal-Wallis rank sum test  ($\chi^2$ = `r signif(k$statistic, 3)`, `r p.function(k$p.value)`). Likewise, pairwise median differences between banker and control conditions (banker median = `r signif(median(df$offer[df$condition=='banker']),3)`, control median = `r signif(median(df$offer[df$condition=='control']),3)`) and customer and control conditions (customer median = `r signif(median(df$offer[df$condition=='customer']),3)`) were re-tested to confirm that our predictions were supported for both banker and customer conditions (banker-control Mann-Whitney U = `r signif(a1$statistic,3)`, `r p.function(a1$p.value)`, and Cliff's Delta = `r signif(cliff.bank$estimate,3)`; customer-control U = `r signif(a2$statistic,3)`, `r p.function(a2$p.value)`, and Cliff's Delta = `r signif(cliff.cust$estimate,3)`).

While the offer variance in the windfall vignette condition was lower than that of the control condition (windfall mean = `r signif(mean(df$offer[df$condition=='windfall']),3)`, SD = `r signif(sd(df$offer[df$condition=='windfall']),3)`, IQR = `r signif(IQR(df$offer[df$condition=='windfall']),3)`; control IQR = `r signif(IQR(df$offer[df$condition=='control']),3)`), this difference was not significant (F = `r signif(lvF, 3)`, `r p.function(lvP)`; $\chi^2$ = `r signif(flig$statistic,3)`, `r p.function(flig$p.value)`) using either equality of variances test (i.e., Brown-Forsythe Levene-type and Fligner-Killeen tests), contrary to predictions. It is worth noting, however, that the portion of "fair splits" (i.e., 50-50 offers) among proposers was `r signif(fc1, 3)`% with an acceptance rate of `r signif(ar1, 3)`% in the control condition, and `r signif(fc2, 3)`% fair splits with an acceptance rate of `r signif(ar2, 3)`% in the windfall condition. 

The probability of offer acceptance was modeled using a logistic regression (Table 3 and Figure 8). The probability of offer acceptance was low for small offers, and increased sharply in the control and windfall conditions as a function of offer amount. The customer and banker conditions had "flatter" acceptance probabilities across offer amounts, although note that the few data points in the high/low offer ranges makes this a dubious distinction. Tjur's coefficient of discrimination, a measure of fit, was D = `r signif(rsq$D, 3)`. Inspection of the distribution of probabilities for true rejections (Figure 9, top) and true acceptances (Figure 9, bottom) indicated that our model was reasonably good at predicting acceptances but poor at predicting rejections. Overall, the responders' acceptance criteria aligned with our predictions: in the control and windfall conditions, responders largely accepted fair 50-50 splits with some tolerance for "hypo-fair" (i.e., < 50%) offers, but most of the latter were rejected. In the banker condition, `r signif(over90, 3)`% of participants offered 90% or more of their allocation, with modes at 90% (n = 13) and 95% (n = 12). When bankers were responders (in the customer condition), `r signif(hypoacc, 3)`% accepted hypo-fair offers (those < 50%). Customers in the responder role, on the other hand (in the banker condition), rejected `r signif(bankrej, 3)`% of hyper-fair offers (those > 50%). In the customer condition, most of the acceptances (and rejections) were hypo-fair, while most acceptances *and rejections* in the banker condition were "hyper-fair" (i.e., > 50%) offers (Figure 10). 


```{r echo=FALSE, warning=FALSE, message=FALSE}
tmp <- tidy(m_accept)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table 3. Logistic regression model of responder acceptance probability as a function of offer amount and condition. Coefficients are log odds. For effects plot, see Figure 8.')
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
visreg(m_accept, xvar='offer', by='condition', scale='response', jitter = TRUE)
```

**Figure 8.** Plot of logistic regression model of responders' acceptance probability as a function of offer amount and condition (gray shaded areas indicate 2 SE, rug indicates offers). Model coefficients are in Table 3.


```{r echo=FALSE, warning=FALSE}
plot_accept
```

**Figure 9.** Plot of fitted probabilities of acceptance in the logistic model that includes experimental condition and offer amount (Figure 8), for true rejections (top) and true acceptances (bottom). If the logistic model has perfect predictability, then true rejections should cluster at 0 and true acceptances should cluster at 1. This logistic model was better at predicting true acceptances (bottom) than true rejections (top). The coefficient of discrimination (Tjur's D) is the difference in the mean probabilities of true acceptances minus the mean probabilities of true rejections. This measure can be used as a logistic regression analogue to an $R^2$ coefficient of determination [@tjur2009].


```{r echo=FALSE, warning=FALSE}
plot_accept_mosaic
```

**Figure 10.** Mosaic plot of frequencies of responders' acceptance and rejection of offers under 50% ("Hypo"), at 50% ("Fair"), and over 50% ("Hyper") by condition.

The proposers' low offer amounts in the customer condition and high offer amounts in the banker condition appeared to be fairly consistent overall with their reported fair currency fees. In particular, most proposers in the customer condition both reported that a fair currency fee was a low percentage amount and offered low percentage amounts to the bankers. In the banker condition, most proposers both reported that a fair currency fee was a low percentage amount and offered high percentage amounts to the customers (i.e., kept a small bank fee - see Figure 11). 

This was true even though most participants reported only moderate familiarity with currency exchange. Pilot study results indicated that there was no meaningful difference in behavior between high- and low-experience individuals (see Tables 3 and 4 in the pilot study supplementary materials). We collected perceived fair fees from institutions that are similar to currency exchange (e.g., ATM fees, broker fees, and service charges) because they might be intuited as conceptually similar to bank fees for currency exchange. In the final study, these amounts were all considered to be fair at < 10% (ATM fees: mean = `r signif(atm.mean,3)`%, SD = `r signif(atm.sd,3)`%; broker fees: mean = `r signif(broker.mean,3)`%, SD = `r signif(broker.sd,3)`%; service charges: mean = `r signif(serv.mean,3)`%, SD = `r signif(serv.sd,3)`%; currency exchange fee: mean = `r signif(cfmean,3)`%, SD = `r signif(cfsd,3)`%). Taken together, this could suggest that individuals with little experience with currency exchange overcome their lack of exposure by conceptualizing this scenario as similar to other "banker-customer" situations.

```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}

plot_fair_actual

```

**Figure 11.** Amount offered (%) among proposers in the banker and customer conditions, as a function of their reported opinions about fair currency fee (%). Conditions are separately represented by color.


The pilot study results (previously discussed) informed our experimental design and caused us to slightly adjust our initial predictions and experimental protocol. To explore the effects of changing our protocol between pilot and experiment, we compare and contrast the results of this experiment to those of the pilot. As discussed in both this section and the "Pilot Study" section, we confirmed our predictions with large effect sizes between control and treatment conditions in both the pilot and the experiment. The offers in both (pilot and experiment) control conditions and both customer conditions did not significantly differ in central tendency (control condition: Mann-Whitney U = `r signif(pexpconmean$statistic,3)`, `r p.function(pexpconmean$p.value)`; customer condition: U = `r signif(pexpcustmean$statistic,3)`, `r p.function(pexpcustmean$p.value)`) or variance (control: Brown-Forsythe Levene F = `r signif(pexpconsdF,3)`, `r p.function(pexpconsdP)`; customer: F = $`r signif(pexpcustsdF,2)`$, `r p.function(pexpcustsdP)`). The banker condition in the experiment, however, yielded higher offers (U = `r signif(pexpbankmean$statistic,3)`, `r p.function(pexpbankmean$p.value)`) with lower offer variance (F = `r signif(pexpbanksdF,3)`, `r p.function(pexpbanksdP)`) than the banker condition in our pilot. The latter had a significantly higher variance than the other conditions in the study, which as discussed, was likely an artifact of confusing instructions (see Pilot Study). These comparisons indicate that the minor adjustments we made to study instructions following the pilot study improved our results (see Figure 12 and supplementary materials for experimental GAMLSS analyses).

```{r echo=FALSE, warning=FALSE}
grid.arrange(plot_pilot, plot_final)
```

**Figure 12.** Distribution of offers in the pilot data (top row) and final study (bottom row). Study instructions were tweaked following the pilot study, which appeared to reduce low offers in the banker condition in the final study. The windfall condition is omitted in this figure because it did not have a corresponding pilot condition.

## Exploratory analyses

We conducted exploratory analyses on both our pilot data and study data. Because participant attrition was a concern (Figure 5 and Phase I supplement), we shortened the study by omitting  exploratory items from the final study when analyses of the pilot data did not reveal strong evidence for theoretically important patterns. In particular, the SVO variable involved 9 items. In the pilot study, individuals classified as “prosocial” according to their SVO score made slightly, but not significantly, larger offers across the three conditions, compared to individuals classified as “individualistic.” As noted in our discussion of pilot study results (Phase I supplement), we would require a much larger sample size to have the power to detect an effect of SVO, if it exists. We therefore omitted the SVO items from the final study. We also omitted the minimum and maximum expected offers, which had little theoretical significance, to further shorten the study.

We retained the other exploratory measures noted in the Methods. Not surprisingly, participants rated the fairness of the outcome significantly lower when offers were rejected than when offers were accepted (M = `r signif(mean(d.temp$fairoutcome[d.temp$accept==0], na.rm=T), 2)` vs. M = `r signif(mean(d.temp$fairoutcome[d.temp$accept==1], na.rm=T), 2)` on a 1-5 point scale, `r p.function(fairout3p)` by Wilcoxon rank test). For responders, the expected payoffs appeared to influence accept/reject decisions. In general, when offers met or exceeded responders' expected payoffs, they were generally inclined to accept, rather than reject (`r p.function(m_diff1_p)`). This effect was less distinct in treatment conditions relative to the control, but this appears to be an artifact of few actual offers below expected offers (i.e., with positive difference scores, where scores = expected payoff - actual offer). Recognition of the UG from previous experience did not have a significant effect on our key findings (`r p.function(m_prevUG_anova_pvalue)`). For details on these results, with additional exploratory analyses, see phase II supplementary materials. 

<!--
Nonetheless, these measures included standard and fair currency fees, broker fees, service charge fees, and ATM fees, expected payoffs, demographic data, emotional responses to the game, experience with currency exchange transactions, and whether or not the participant recognized the task as a bargaining game from previous experience. We outline these results, with an experimental GAMLSS analysis of our treatment distributions, for the interested reader in the experimental supplementary materials. -->





## Discussion

```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}
plot_effect_sizes
```

**Figure 13.** Effect sizes (absolute values of Cohen's d) from this study (denoted by "**") and a representative sample of previous framing studies. Colors represent game type and bars indicate 95% CI. For reference, d = 0.8 is considered a large effect by convention.

# Supplementary materials (Phase II)

Using our *a priori* exclusion criteria, we omitted data from `r signif(omitperc,3)`% of participants who made an offer in the UG. It is therefore important to assess how the excluded offers differed from the included offers. Figure 6 depicts the distributions of offers of excluded vs. included participants, revealing a large difference between them only in the control and windfall conditions: `r 100*signif(in50, 2)`% of the included participants offered 50% and only `r 100*signif(in0, 2)`% offered 0%; in contrast, `r 100*signif(out50, 2)`% of excluded participants offered 50% and `r 100*signif(out0, 2)`% offered 0%). 

These differences had only a marginal impact on our main results. We fitted a model of offers by condition that included all participants (N = `r nobs(m_included_excluded)` instead of N = `r nrow(UG.data)`). Results were nearly identical to those depicted in Table 2 and Figure 7. We also fitted a model with an additional variable that indicated excluded status. The main effect of condition was still highly significant, there was no significant main effect of exclusion on offers, and there was only a marginally significant exclusion X condition interaction (`r p.function(m_included_excluded_pvalue)`), probably due to the windfall condition (see Figure S1). We do not have a good explanation for the propensity of excluded participants to offer 0% in the control and windfall conditions. Many control and windfall participants who opted out immediately after the game/before the survey had low offers and high rejection rates (`r signif(quitrej,3)`% rejected, mean = `r signif(quitoffer,3)`%), and most others were excluded for their failure to pass attention checks. 

```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}
plot(allEffects(m_included_excluded), main='', ylab='offer')
#Anova(m, 3)
#summary(m)
```

**Figure S1.** Generalized linear model of offers by condition and included vs. excluded status. Error bars indicate +/- 2 SE.


```{r echo=FALSE, warning=FALSE}
tmp <- tidy(m_included_excluded_anova)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table S1. ANOVA results for condition X excluded results.')
```


```{r echo=FALSE, warning=FALSE}
tmp <- tidy(m_included_excluded)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table S2. Summary results for condition X excluded results.')
```


```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}
ggplot(subset(df, (condition=='banker' | condition=='customer') & 
                playerid==2), aes(x=offer)) + 
  geom_histogram() + facet_grid(condition~accept)
```

**Figure S2.** Histograms of offer amounts in the currency exchange treatment conditions by condition and responders' acceptance status (1 = accepted, 0 = rejected). 

```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}
ggplot(subset(df, (condition=='control' | condition=='windfall') & 
                playerid==2), aes(x=offer)) + 
  geom_histogram() + facet_grid(condition~accept)
```

**Figure S3.** Histograms of offer amounts in the control and windfall conditions by condition and responders' acceptance status (1 = accepted, 0 = rejected). 


## Exploratory measures

Responders' expected payoffs influenced their probability of acceptance, such that offers exceeding expectations (expectation - offer < 0) were more readily accepted than offers below expectations (expectation - offer > 0). This trend was particularly distinct in the control condition, though indistinct trends in the treatment conditions are limited by the fewer offers below expectations (Table S3 and Figure S4). A potentially useful diagnostic measure was a survey question asking participants if they recognized the game as a bargaining game from previous experience. Offer trends among "yes" and "no" responses were not significantly different (Figure S7). Overall, `r signif(p.recUG,3)`% of participants recognized the UG, and this number was < 25% in all experimental conditions and among proposers and responders (Figure S8). We also measured expectations with a survey question asking what participants expected to receive as a payoff (Figure S9), though it is not clear whether the participants interpreted this question as either total payoff (UG earnings + \$0.25 participation fee) or UG earnings alone. Perhaps more importantly, we asked participants if they thought that the outcome of the experiment was fair. Any glaringly high rates of dissatisfaction after, e.g., a treatment condition or solely among proposers or responders could have reflected any unfair framing practices or unintentional confusion in our vignette approach. We find that participants were not dissatisfied on average across roles any of the control nor treatment conditions, nor were the proposers or responders uniquely dissatisfied in any particular condition (Figure S10, Table S5).

```{r echo=FALSE, warning=FALSE}
tmp <- tidy(m_diff)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table S3. Logistic regression model of difference scores (expected offer minus actual offer) among responders by condition. Estimates are log odds. The base condition is the control condition. See Figure S4 for an effects plot.')
```


```{r echo=FALSE, warning=FALSE, message=FALSE}
visreg(m_diff, xvar='diff_score', by='condition', scale='response', jitter = TRUE, xlab='expectation - offer')
```

**Figure S4.** Plot of logistic regression model of responders' acceptance probability as a function of difference scores (expected offer minus actual offer) among responders by condition (gray shaded areas indicate 2 SE, rug indicates offers). Model coefficients are in Table S3.


```{r echo=FALSE, warning=FALSE}
# "experience with currency conversion"
d.temp$forex_exp <- as.integer(d.temp$forex_exp)
ggplot(d.temp, aes(x=forex_exp)) + stat_count() +
  facet_grid(playerid~condition)

```

**Figure S5.** Likert scale responses to level of experience (1 = no experience at all, 5 = extensive experience) with currency conversion by condition and role (1 = proposer, 2 = responder).


```{r echo=FALSE, warning=FALSE}


# "experience with international travel"
d.temp$travel_exp <- as.integer(d.temp$travel_exp)
ggplot(d.temp, aes(x=travel_exp)) + stat_count() +
  facet_grid(playerid~condition)
```

**Figure S6.** Likert scale responses to level of experience (1 = no experience at all, 5 = extensive experience) with international travel by condition and role (1 = proposer, 2 = responder).


```{r echo=FALSE, warning=FALSE}
tmp <- tidy(m_diff)
tmp$p.value <- p.function(tmp$p.value)
kable(tmp, digits = 2, caption = 'Table S4. Logistic regression model of mean offers by condition and recognition of the UG from previous experience. Estimates are log odds. The base condition is the control condition. See Figure S7 for an effects plot.')
```

```{r echo=FALSE, warning=FALSE}
plot(allEffects(m_prevUG), ylab='offer', main='')
```

**Figure S7.** Effect plot of the mean offer (as a proportion of the maximum possible offer) by condition and recognition of the UG. Bars indicate +/- 2 SE. Model coefficients are in Table S4. See text for details.


```{r echo=FALSE, warning=FALSE}
# "did you recognize this as a bargaining game from previous experience?"
ggplot(df) + 
  geom_mosaic(aes(x=product(condition), fill=factor(recognizeUG))) +
  facet_grid(~playerid) + 
  theme(axis.text.x=element_text(angle=-30, hjust= .1)) + 
  guides(fill=guide_legend(title = "Fairness", reverse = TRUE)) +
  labs(x="Condition",y="Frequency")
```

**Figure S8.** Frequencies of "yes" vs. "no" responses to the question about whether or not participants recognized the UG from previous experience, by condition and role (1 = proposer, 2 = responder).


```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}
# what did you expect to receive as a payoff? **ambiguity about +0.25??
ggplot(df, aes(x=offerexp)) + geom_histogram() + 
  facet_grid(playerid~condition)
#ggplot(df, aes(x=condition, y=offerexp)) + geom_boxplot() +
 # facet_wrap(~playerid)
```

**Figure S9.** Histogram of responses to the question about what participants expected to receive as a payoff in the task they completed, by condition and role (1 = proposer, 2 = responder).


```{r echo=FALSE, warning=FALSE}
ggplot(d.temp, aes(x=fairoutcome)) + stat_count() + 
  facet_grid(playerid~condition)
```

**Figure S10.** Likert scale responses to the statement that participants thought that the outcome of the game was fair (1 = strongly disagree, 5 = strongly agree) by condition and role (1 = proposer, 2 = responder).


```{r echo=FALSE, warning=FALSE}
kable(outdf, digits = 2, caption = 'Table S5. Summary results for participant opinions about fairness of game outcomes.')
```


In the pilot study, we used our GAMLSS analyses as a diagnostic to construct mixture models in our widely varying treatment distributions. To be thorough, we include these for the experimental study and note that both treatment conditions consist only of two distribution clusters rather than the problematic three seen in the pilot study (each around our predicted values and a 50-50 offer - see Figures S11 and S12). This is also apparent in the Results section (Figure 11), and we discuss these particular deviations from our predictions at some length in the Discussion section.


```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}

dc$offer2 <- dc$offer/100
#m <- gamlssMX(offer2 ~ 1, 
 #             data = na.omit(subset(df, condition=='banker')), 
  #            family=c(NO, BEINF, BEINF), K=3)
m <- gamlssMX(offer2 ~ 1, 
              data = na.omit(subset(dc, condition=='banker')), 
              family=c(NO, BEINF), K=2)

```

```{r fig.width=10, fig.height=7, echo=FALSE, warning=FALSE}

pdf.plot(
  family = NO,
  min = 0,
  max = 1,
  step = 0.01,
  mu = c(
    invlogit(m$models[[1]]$mu.coefficients)
  ),
  sigma = c(
    invlogit(m$models[[1]]$sigma.coefficients)
  ), 
  #allinone = TRUE,
  no.title = TRUE
)
pdf.plot(
  family = BEINF,
  min = 0,
  max = 1,
  step = 0.01,
  mu = invlogit(m$models[[2]]$mu.coefficients),
  sigma = invlogit(m$models[[2]]$sigma.coefficients),
  nu = exp(m$models[[2]]$nu.coefficients),
  tau = exp(m$models[[2]]$tau.coefficients),
  no.title = TRUE
)



```

**Figure S11.** Mixture model for offer distribution in banker condition using expectation maximization to determine 2 constitutive distributions (top-bottom: normal: mu = `r signif(invlogit(m$models[[1]]$mu.coefficients),3)`, sigma = `r signif(invlogit(m$models[[1]]$sigma.coefficients),3)`; inflated beta: mu = `r signif(invlogit(m$models[[2]]$mu.coefficients),3)`, sigma = `r signif(invlogit(m$models[[2]]$sigma.coefficients),3)`, nu = $`r signif(exp(m$models[[2]]$nu.coefficients),3)`$, tau = `r signif(exp(m$models[[2]]$tau.coefficients),3)`).



```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE}

m <- gamlssMX(offer2 ~ 1, 
              data = na.omit(subset(dc, condition=='customer')), 
              family=c(NO, BEINF), K=2)
```

```{r fig.width=10, fig.height=7, echo=FALSE, warning=FALSE}



pdf.plot(
  family = NO,
  min = 0,
  max = 1,
  step = 0.01,
  mu = c(
    invlogit(m$models[[1]]$mu.coefficients)
  ),
  sigma = c(
    invlogit(m$models[[1]]$sigma.coefficients)
  ),
  no.title = TRUE
)
pdf.plot(
  family = BEINF,
  min = 0,
  max = 1,
  step = 0.01,
  mu = invlogit(m$models[[2]]$mu.coefficients),
  sigma = invlogit(m$models[[2]]$sigma.coefficients),
  nu = exp(m$models[[2]]$nu.coefficients),
  tau = exp(m$models[[2]]$tau.coefficients),
  no.title = TRUE
)

```

**Figure S12.** Mixture model for offer distribution in customer condition using expectation maximization to determine 2 constitutive distributions (top-bottom: normal: mu = `r signif(invlogit(m$models[[1]]$mu.coefficients),3)`, sigma = `r signif(invlogit(m$models[[1]]$sigma.coefficients),3)`; inflated beta: mu = `r signif(invlogit(m$models[[2]]$mu.coefficients),3)`, sigma = `r signif(invlogit(m$models[[2]]$sigma.coefficients),3)`, nu = $`r signif(exp(m$models[[2]]$nu.coefficients),3)`$, tau = `r signif(exp(m$models[[2]]$tau.coefficients),3)`).



## References





